#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Jan  4 17:18:37 2023

@author: aixuexi
"""
import matplotlib.pyplot as plt
from matplotlib import rcParams

import os
import time
import math
import copy
import json
import pickle
import pandas as pd
import prettytable as pt
import seaborn as sns
import numpy as np
import random
import sklearn
from sklearn import decomposition

import statsmodels.api as sm

import pyecharts.options as op
from pyecharts import options as opts
from pyecharts.charts import Radar

from MyQPModel.bbvi_em_policy_mp2 import *
from MyQPModel.utils_Mcoop_split import *
from MyQPModel_Results.utils_predict import *



def pca_reduce_dim(X, n_components):
    pca = decomposition.PCA(n_components=n_components)
    pca.fit(X)
    print("方差解释力: ", pca.explained_variance_ratio_)
    X_reduce = pca.transform(X) # 降维
    return X_reduce, pca, pca.explained_variance_ratio_


def get_empirical_data(save_path, file_name, beforeyear):
    '''
    获取实证分析数据 (不考虑合作关系)
    '''
    # 读取实证数据 --- 由mag_aid.py生成
    # targeted_aid = read_file(os.path.join(save_path, "empirical_data.pkl"))
    # save_file(targeted_aid, os.path.join(ResultsPath, "empirical_data({}).pkl".format(file_name)))
    
    targeted_aid = read_file(os.path.join(ResultsPath, "empirical_data({}).pkl".format(file_name)))
    
    # 训练集确定:
    pi_num = 5
    data   = dict()
    for k, aid in enumerate(targeted_aid):
        cclist, pidlist = sort_aid_cc(targeted_aid[aid]['x_obs'], beforeyear)  # 每位作者截止至beforeyear的发文质量(tcc)列表
        if len(cclist) == 0:
            continue
        
        x  = list()
        pi = list()
        for pid, cc in zip(pidlist, cclist):
            x.append(np.log(cc + 1))
            pi.append(np.zeros(pi_num))
        x  = np.array(x)
        pi = np.array(pi)
        
        data[k]        = dict()
        data[k]['x']   = x
        data[k]['pi']  = pi
        data[k]['aid'] = aid
        data[k]['pid'] = pidlist
        
    # 识别策略 (M_pi)
    pid2pi = dict()  # Key: pid ; Value: 策略执行情况 (0 or 1变量)
    for k in data:
        for pid in data[k]['pid']:
            pid2pi[pid] = np.zeros(pi_num)
    # 读取 PCA 结果
    pca_dict = read_file(os.path.join(save_path, "pca_dict.pkl"))
    
    metrics_name = "DS"
    median = pca_dict[metrics_name]["median"]
    pos    = pca_dict[metrics_name]["pos"]
    pid2DS = read_file(os.path.join(save_path, "pid2DS.pkl"))
    miss   = 0
    for pid in pid2pi:
        if pid in pid2DS:
            DS = pid2DS[pid]
        else:
            miss += 1
            continue
        if pos == "+":                           # ***单调性保持
           if DS > median:
               pid2pi[pid][0] = 1
           else:
               pid2pi[pid][0] = 0
        if pos == "-":                           # ***单调性逆反
           if DS < median:
               pid2pi[pid][0] = 1
           else:
               pid2pi[pid][0] = 0
    del pid2DS
        
    metrics_name = "PS"
    median = pca_dict[metrics_name]["median"]
    pos    = pca_dict[metrics_name]["pos"]
    pid2PS = read_file(os.path.join(save_path, "pid2PS.pkl"))
    miss   = 0
    for pid in pid2pi:
        if pid in pid2PS:
            PS = pid2PS[pid]
        else:
            miss += 1
            continue
        if pos == "+":                           # ***单调性保持
           if PS < median:
               pid2pi[pid][1] = 1
           else:
               pid2pi[pid][1] = 0
        if pos == "-":                           # ***单调性逆反
           if PS > median:
               pid2pi[pid][1] = 1
           else:
               pid2pi[pid][1] = 0
    del pid2PS
        
    metrics_name = "MS"
    median = pca_dict[metrics_name]["median"]
    pos    = pca_dict[metrics_name]["pos"]
    pid2MS = read_file(os.path.join(save_path, "pid2MS.pkl"))
    miss   = 0
    for pid in pid2pi:
        if pid in pid2MS:
            MS = pid2MS[pid]
        else:
            miss += 1
            continue
        if pos == "+":                           # ***单调性保持
           if MS < median:
               pid2pi[pid][2] = 1
           else:
               pid2pi[pid][2] = 0
        if pos == "-":                           # ***单调性逆反
           if MS > median:
               pid2pi[pid][2] = 1
           else:
               pid2pi[pid][2] = 0
    del pid2MS       
    
    metrics_name = "ES"
    median = pca_dict[metrics_name]["median"]
    pos    = pca_dict[metrics_name]["pos"]
    pid2ES = read_file(os.path.join(save_path, "pid2ES.pkl"))
    miss   = 0
    for pid in pid2pi:
        if pid in pid2ES:
            ES = pid2ES[pid]
        else:
            miss += 1
            continue
        if pos == "+":                           # ***单调性保持
           if ES < median:
               pid2pi[pid][3] = 1
           else:
               pid2pi[pid][3] = 0
        if pos == "-":                           # ***单调性逆反
           if ES > median:
               pid2pi[pid][3] = 1
           else:
               pid2pi[pid][3] = 0
    del pid2ES  
    
    metrics_name = "CS"
    median = pca_dict[metrics_name]["median"]
    pos    = pca_dict[metrics_name]["pos"]
    pid2CS = read_file(os.path.join(save_path, "pid2CS.pkl"))
    miss   = 0
    for pid in pid2pi:
        if pid in pid2CS:
            CS = pid2CS[pid]
        else:
            miss += 1
            continue
        if pos == "+":                           # ***单调性保持
           if CS < median:
               pid2pi[pid][4] = 1
           else:
               pid2pi[pid][4] = 0
        if pos == "-":                           # ***单调性逆反
           if CS > median:
               pid2pi[pid][4] = 1
           else:
               pid2pi[pid][4] = 0      
    total_nop = len(pid2CS)
    del pid2CS  
    
    # 计算M_pi
    M_pi = list()
    for k in data:
        pidlist = data[k]['pid']
        pi = list()
        for pid in pidlist:
            pi.append(pid2pi[pid])
        pi = np.array(pi)
        data[k]['pi'] = pi
        
        del data[k]['pid']
        M_pi.append(pi)
    M_pi  = np.concatenate(M_pi)
    ratio = np.sum(M_pi, axis=0) / len(M_pi)
    
    print("领域: {}".format(file_name))
    print("年份: {}".format(beforeyear))
    print("结果存放路径: {}".format(ResultsPath))
    print("该领域的总论文数目: {}".format(total_nop))
    print("实证分析中学者数目: {}".format(len(targeted_aid)))
    print("实证分析中学者撰写的论文数目: {}".format(len(pid2pi)))
    print("待分析学者数目: {}".format(len(data)))
    print("策略执行比率: DS {:.3f}, PS {:.3f}, MS {:.3f}, ES {:.3f}, CS {:.3f}".format(*ratio))
    print("\n")
    return data


def BBVI_Algorithm_For_EmpiricalAnalysis(save_path, file_name, beforeyear):
    
    mp_num = 8
    data   = get_empirical_data(save_path, file_name, beforeyear)
    datas  = split_data(data, mp_num)
    
    # 极大似然估计 - 简单求平均
    var_params_init, model_params_init = max_likelihoood(data)
    
    # 贝叶斯后验估计
    Epochs      = 10
    step_size   = 1e-1
    num_iters   = 100
    num_samples = 1
    var_params, model_params = var_params_init, model_params_init
    
    for e in range(Epochs):
        # E-Step
        print("({}) Optimizing variational parameters...".format(e))           
        E_start_time    = time.perf_counter()
        var_params_next = Estep_MP(datas, model_params, var_params, num_samples, step_size, num_iters)
        E_end_time      = time.perf_counter()                      
        var_params      = var_params_next
        print("Estep 耗时: {:.4f}".format(E_end_time-E_start_time))
        
        # M-Step
        print("({}) Optimizing model parameters...".format(e))
        M_start_time      = time.perf_counter()
        model_params_next = Mstep_MP(datas, model_params, var_params, num_samples, step_size, num_iters)
        M_end_time        = time.perf_counter()
        model_params      = model_params_next
        print("Estep 耗时: {:.4f}".format(M_end_time-M_start_time))
        
    # 变分参数估计 - BBVI-EM
    var_params_bbvi, model_params_bbvi = var_params, model_params
    var_params_init, model_params_init = max_likelihoood(data)
    
    # 存放结果
    aid2Q_OUR        = dict()
    model_params_OUR = model_params_bbvi
    var_params_q     = var_params_bbvi[0]
    var_params_e     = var_params_bbvi[1]
    for k in data:
        aid = data[k]['aid']
        q   = var_params_q[k, :]
        e   = var_params_e[k, :]
        aid2Q_OUR[aid] = (q, e)
    
    results_OUR = (model_params_OUR, aid2Q_OUR)
    save_file(results_OUR, os.path.join(ResultsPath, "OUR_{}_{}.pkl".format(file_name, beforeyear)))
    # results_WSB = (model_params_WSB, aid2Q_WSB)
    # save_file(results_WSB, os.path.join(ResultsPath, "WSB_{}_{}.pkl".format(file_name, beforeyear)))


def train_reserach_strategy_q_model():
    beforeyear = 2010 # beforeyear 之前的被用作训练数据
    for file_name in ["physics", "chemistry", "computer science"]:
        save_path = "/mnt/disk2/EmpiricalData/StatisticalData_{}".format(file_name)
        # 介绍数据集
        data   = get_empirical_data(save_path, file_name, beforeyear)
        # 执行research strategy Q model
        BBVI_Algorithm_For_EmpiricalAnalysis(save_path, file_name, beforeyear)


def get_author_name(beforeyear):
    # 获取待分析的aid的姓名
    aid2name = dict()
    beforeyear = 2010 # beforeyear 之前的被用作训练数据
    for file_name in ["physics", "chemistry", "computer science"]:
        save_path = "/mnt/disk2/EmpiricalData/StatisticalData_{}".format(file_name)
        data = get_empirical_data(save_path, file_name, beforeyear)
        for i in data:
            aid = data[i]['aid']
            aid2name[aid] = ("", "")
            
    for i in tqdm(range(5)):
        mag_authors_file = "/mnt/disk2/MAG_DATA_SET/MAGv2.1-authors"
        file_i = "mag_authors_{}.txt".format(i)
        with open(os.path.join(mag_authors_file, file_i), 'r', encoding='utf8') as f:
            while True:
                oneline = f.readline().strip()
                if oneline:
                    oneline_json = json.loads(oneline)
                    aid = oneline_json['id']
                    if aid in aid2name:
                        name = oneline_json['name']
                        normalized_name = oneline_json['normalized_name']
                        aid2name[aid] = (name, normalized_name)
                else:
                    break
    save_file(aid2name, os.path.join(ResultsPath, "aid2name.pkl"))
        
    
#%%
def calculate_metrics_pearsonr(metrics_list, columns_name, title):
    ''' 计算上述所有指标的pearsonr '''
    # pd dataframe
    all_metrics         = np.array(metrics_list).T
    all_metrics         = pd.DataFrame(all_metrics)
    # all_metrics.columns = columns_name
    
    # 计算 pearsonr
    matrix = all_metrics.corr()
    mask   = np.triu(np.ones_like(matrix, dtype=np.bool))
    corr   = matrix.copy()
    
    # 绘制热力图
    fig = plt.figure(figsize=(10, 8))
    plt.rcParams['savefig.dpi'] = 300
    plt.rcParams['figure.dpi'] = 300
    config = {
              "font.family" : "Times New Roman", # # SimHei
              "font.size" : 14
              }
    rcParams.update(config)
    # SimHei 字体符号不正常显示
    plt.rcParams['axes.unicode_minus'] = False 
    
    cmap = sns.diverging_palette(0, 230, 90, 60, as_cmap=True)
    sns.heatmap(corr, mask=mask, annot=True, fmt='.2f', cmap=cmap,
                vmin=-1, vmax=1, cbar_kws={'shrink': 1}, linewidths=5, square=True,
                xticklabels=columns_name, yticklabels=columns_name)
    plt.yticks(rotation=0) 
    plt.title(title, fontsize=25)


def compute_rank_table(aid_list, 
                       q_mu_list, 
                       DS_mu_list, PS_mu_list, MS_mu_list, ES_mu_list, CS_mu_list):
    # 获取每种能力排序前10的学者
    aid2name = read_file(os.path.join(ResultsPath, "aid2name.pkl"))
    
    top = 10
    def rank_top(aid_list, q_mu_list):
        noa = len(aid_list)
        tmp_list = [(aid2name[aid_list[i]][0], q_mu_list[i]) for i in range(noa)]
        tmp_list = sorted(tmp_list, key=lambda x: x[-1], reverse=True)
        return tmp_list[:top]
    
    q_top  = rank_top(aid_list, q_mu_list)
    ds_top = rank_top(aid_list, DS_mu_list)
    ps_top = rank_top(aid_list, PS_mu_list)
    ms_top = rank_top(aid_list, MS_mu_list)
    es_top = rank_top(aid_list, ES_mu_list)
    cs_top = rank_top(aid_list, CS_mu_list)
    
    tb = pt.PrettyTable()
    tb.field_names = ["Rank", "Q", "MS", "PS", "DS", "ES", "CS"]
    for i in range(top):
        q_row  = "{}({:.3f})".format(*q_top[i])
        ds_row = "{}({:.3f})".format(*ds_top[i])
        ps_row = "{}({:.3f})".format(*ps_top[i])
        ms_row = "{}({:.3f})".format(*ms_top[i])
        es_row = "{}({:.3f})".format(*es_top[i])
        cs_row = "{}({:.3f})".format(*cs_top[i])
        tb.add_row([i + 1, q_row, ms_row, ps_row, ds_row, es_row, cs_row])
    print(tb)
    
    f = open(os.path.join(ResultsPath, "compute_rank_table.txt"), 'w')
    for i in range(top):
        q_row  = "{}({:.3f})".format(*q_top[i])
        ds_row = "{}({:.3f})".format(*ds_top[i])
        ps_row = "{}({:.3f})".format(*ps_top[i])
        ms_row = "{}({:.3f})".format(*ms_top[i])
        es_row = "{}({:.3f})".format(*es_top[i])
        cs_row = "{}({:.3f})".format(*cs_top[i])
        f.write("{}\t{}\t{}\t{}\t{}\t{}\n".format(q_row, ms_row, ps_row, ds_row, es_row, cs_row))
    f.close()
    
    
if __name__ == "__main__":
    # 结果存放路径
    ResultsPath = "./Results/Results_policy"  

    def main():
        '''
        # (1) 选题策略的特征识别: 增强策略, 减弱策略, 随机策略 - 根据策略效率系数 > 0; <0; =0
        # (2) 选题策略偏好与科研能力的关系: q 与 Prob(pi)
        # (2) 选题策略效率与科研能力的关系: q 与 e
        '''
        titles = {
            "physics": "物理学", 
            "chemistry": "化学", 
            "computer science": "计算机科学"
        }
        
        beforeyear = 2000
        beforeyear_end = 2010
        file_name = 'chemistry'
        title = titles[file_name]
        
        # 读取参数估计结果
        results_OUR = read_file(
            os.path.join(
                ResultsPath, 
                "OUR_{}_{}.pkl".format(file_name, beforeyear)
            )
        )
        model_params_OUR, aid2Q_OUR = results_OUR
        
        # Table 6.
        tb = pt.PrettyTable()
        tb.field_names = ["选题策略", "策略效率均值", "策略效率标准差"]
        pi_name_list   = ["DS", "PS", "MS", "ES", "CS"]
        for i, pi_name in enumerate(pi_name_list):
            pi_mu, pi_log_std = model_params_OUR[i]
            tb.add_row([pi_name, "{:.4f}".format(pi_mu), "{:.4f}".format(np.exp(pi_log_std))])
        print(tb)
    
        # # 选题策略偏好与科研能力的关系: q 与 Prob(pi)
        # save_path = "/mnt/disk2/EmpiricalData/StatisticalData_{}".format(file_name)
        # data = get_empirical_data(save_path, file_name, beforeyear_end)
        # pi_pref = dict()
        # # traditional author level evaluation metrics
        # trad_al_eval = dict() 
        # for k in tqdm(data):
        #     aid = data[k]['aid']
        #     pi_k = data[k]['pi']
        #     pi_pref_k = np.sum(pi_k, axis=0) / len(pi_k)
        #     pi_pref[aid] = pi_pref_k
        #     x = data[k]['x']
        #     obs_cc = np.exp(x) - 1
        #     H_k = calculate_h_index(obs_cc)  # h指数
        #     N_k = len(obs_cc)  # 发文量
        #     C_k = sum(obs_cc)  # 累计引用数目
        #     CS_k = max(obs_cc)  # 最大引用数目
        #     trad_al_eval[aid] = (N_k, C_k, CS_k, H_k)
        # save_file(trad_al_eval, os.path.join(ResultsPath, "TRAD({}).pkl".format(file_name)))
        
        trad_al_eval = read_file(os.path.join(ResultsPath, "TRAD({}).pkl".format(file_name)))
        
        
        # 选题策略效率与科研能力的关系: q 与 e
        aid_list    = list()
        # independent variable
        q_mu_list   = list()
        q_std_list  = list()
        # benefit degree
        DS_mu_list  = list()
        PS_mu_list  = list()
        MS_mu_list  = list()
        ES_mu_list  = list()
        CS_mu_list  = list()
        # risk degree
        DS_std_list = list()
        PS_std_list = list()
        MS_std_list = list()
        ES_std_list = list()
        CS_std_list = list()
        # research perference
        DS_pref_list = list()
        PS_pref_list = list()
        MS_pref_list = list()
        ES_pref_list = list()
        CS_pref_list = list()
        # dependent variable
        N_list  = list()
        C_list  = list()
        CS_list = list()
        H_list  = list()
        for aid in aid2Q_OUR:
            aid_list.append(aid)
            #
            var_params_q = aid2Q_OUR[aid][0]
            var_params_e = aid2Q_OUR[aid][1]
            # 学者科研能力的均值和方差
            q_mu,  q_log_std  = var_params_q
            # 学者选题效率的均值和方差
            DS_mu, DS_log_std = var_params_e[0, :]
            PS_mu, PS_log_std = var_params_e[1, :]
            MS_mu, MS_log_std = var_params_e[2, :]  
            ES_mu, ES_log_std = var_params_e[3, :]
            CS_mu, CS_log_std = var_params_e[4, :]
            # 策略偏好
            pi_pref_k = pi_pref[aid]
            # 传统评价指标
            N_k, C_k, CS_k, H_k = trad_al_eval[aid]
            
            # 学者科研能力属性
            q_mu_list.append(q_mu)
            q_std_list.append(np.exp(q_log_std))
            # 学者策略效率属性
            # DS_mu_list.append(np.exp(DS_mu))
            # PS_mu_list.append(np.exp(PS_mu))
            # MS_mu_list.append(np.exp(MS_mu))
            # ES_mu_list.append(np.exp(ES_mu))
            # CS_mu_list.append(np.exp(CS_mu))
            DS_mu_list.append(DS_mu)
            PS_mu_list.append(PS_mu)
            MS_mu_list.append(MS_mu)
            ES_mu_list.append(ES_mu)
            CS_mu_list.append(CS_mu)
            
            # 学者策略效率属性
            DS_std_list.append(np.exp(DS_log_std))
            PS_std_list.append(np.exp(PS_log_std))
            MS_std_list.append(np.exp(MS_log_std))
            ES_std_list.append(np.exp(ES_log_std))
            CS_std_list.append(np.exp(CS_log_std))
            # 学者选题策略偏好属性
            DS_pref_list.append(pi_pref_k[0])
            PS_pref_list.append(pi_pref_k[1])
            MS_pref_list.append(pi_pref_k[2])
            ES_pref_list.append(pi_pref_k[3])
            CS_pref_list.append(pi_pref_k[4])
            #
            N_list.append(N_k)
            C_list.append(C_k)
            CS_list.append(CS_k)
            H_list.append(H_k)
    
    
        # Figure 2, Figure 3
        # (1) 计算 Pearsonr - 
        metrics_list = [
            q_mu_list,   
            DS_pref_list, PS_pref_list, MS_pref_list, ES_pref_list, CS_pref_list,
            DS_mu_list,   PS_mu_list,   MS_mu_list,   ES_mu_list,   CS_mu_list
        ]
        name_list = [
            r'$Q_{\alpha}$',           
            r"$r_{\alpha, \pi_{D}}^+$", r"$r_{\alpha, \pi_{P}}^+$", r"$r_{\alpha, \pi_{M}}^+$", r"$r_{\alpha, \pi_{E}}^+$", r"$r_{\alpha, \pi_{C}}^+$",
            r"$E^{\pi_{D}}_{\alpha}$",  r"$E^{\pi_{P}}_{\alpha}$",  r"$E^{\pi_{M}}_{\alpha}$",  r"$E^{\pi_{E}}_{\alpha}$",  r"$E^{\pi_{C}}_{\alpha}$"
        ]
        calculate_metrics_pearsonr(metrics_list, name_list, file_name)
        # 计算 Pearsonr - Figure 2
        metrics_list = [
            q_mu_list, 
            DS_mu_list, PS_mu_list, MS_mu_list, ES_mu_list, CS_mu_list,
            N_list, C_list, CS_list, H_list]
        name_list = [
            r'$Q_{\alpha}$',           
            r"$E^{\pi_{D}}_{\alpha}$",  r"$E^{\pi_{P}}_{\alpha}$",  r"$E^{\pi_{M}}_{\alpha}$",  r"$E^{\pi_{E}}_{\alpha}$",  r"$E^{\pi_{C}}_{\alpha}$",
            r"$N_{\alpha}$", r"$C_{\alpha}$", r"$C_{\alpha}^{*}$", r"$H_{\alpha}$"
        ]  
        calculate_metrics_pearsonr(metrics_list, name_list, file_name)
        # 计算 Pearsonr - Figure 3
        metrics_list = [
            q_mu_list, 
            DS_mu_list, PS_mu_list, MS_mu_list, ES_mu_list, CS_mu_list,
            DS_pref_list, PS_pref_list, MS_pref_list, ES_pref_list, CS_pref_list
        ]
        name_list = [
            r'$Q_{\alpha}$',           
            r"$E^{\pi_{D}}_{\alpha}$",  r"$E^{\pi_{P}}_{\alpha}$",  r"$E^{\pi_{M}}_{\alpha}$",  r"$E^{\pi_{E}}_{\alpha}$",  r"$E^{\pi_{C}}_{\alpha}$",
            r"$p_{\alpha}^{\pi_{D}}$",  r"$p_{\alpha}^{\pi_{P}}$",  r"$p_{\alpha}^{\pi_{M}}$",  r"$p_{\alpha}^{\pi_{E}}$",  r"$p_{\alpha}^{\pi_{C}}$"
        ] 
        calculate_metrics_pearsonr(metrics_list, name_list, file_name)
    
    
        # (2) Figure - 4 案例雷达图
        Q_MAX,  Q_MIN  = np.round(np.max(q_mu_list),  3), np.round(np.min(q_mu_list),  3)
        MS_MAX, MS_MIN = np.round(np.max(MS_mu_list), 3), np.round(np.min(MS_mu_list), 3)
        PS_MAX, PS_MIN = np.round(np.max(PS_mu_list), 3), np.round(np.min(PS_mu_list), 3)
        DS_MAX, DS_MIN = np.round(np.max(DS_mu_list), 3), np.round(np.min(DS_mu_list), 3)
        ES_MAX, ES_MIN = np.round(np.max(ES_mu_list), 3), np.round(np.min(ES_mu_list), 3)
        CS_MAX, CS_MIN = np.round(np.max(CS_mu_list), 3), np.round(np.min(CS_mu_list), 3)
        
        cases = [49, 1, 10, 11] # 物理学案例: 9(MS是短板) # 10 (被1号全方位优势) # 0 46
        # cases = [36, 1, 4, 15]  # 化学案例
        # cases = [37, 8, 16, 46]  # 29 38*
        cases_ability = list()
        cases_Q       = list()
        for i in cases:
            aid = list(aid2Q_OUR.keys())[i]
            var_params_q = aid2Q_OUR[aid][0]
            var_params_e = aid2Q_OUR[aid][1]
            # 学者科研能力的均值和方差
            q_mu,  q_log_std  = var_params_q
            # 学者选题效率的均值和方差
            DS_mu, DS_log_std = var_params_e[0, :]
            PS_mu, PS_log_std = var_params_e[1, :]
            MS_mu, MS_log_std = var_params_e[2, :]  
            ES_mu, ES_log_std = var_params_e[3, :]
            CS_mu, CS_log_std = var_params_e[4, :]
            # 科研能力标准化到0-1
            Q_norm = (q_mu - Q_MIN) / (Q_MAX - Q_MIN)
            Q_norm = np.round(Q_norm, 2)
            cases_Q.append(Q_norm)
            # 策略效率标准化到0-1
            MS_mu_norm = (MS_mu - MS_MIN) / (MS_MAX - MS_MIN)
            PS_mu_norm = (PS_mu - PS_MIN) / (PS_MAX - PS_MIN)
            DS_mu_norm = (DS_mu - DS_MIN) / (DS_MAX - DS_MIN)
            ES_mu_norm = (ES_mu - ES_MIN) / (ES_MAX - ES_MIN)
            CS_mu_norm = (CS_mu - CS_MIN) / (CS_MAX - CS_MIN)
            MS_mu_norm = np.round(MS_mu_norm, 2)
            PS_mu_norm = np.round(PS_mu_norm, 2)
            DS_mu_norm = np.round(DS_mu_norm, 2)
            ES_mu_norm = np.round(ES_mu_norm, 2)
            CS_mu_norm = np.round(CS_mu_norm, 2)
            
            abilities = [MS_mu_norm, PS_mu_norm, DS_mu_norm, ES_mu_norm, CS_mu_norm]
            cases_ability.append(abilities)
        cases_Q       = np.array(cases_Q)
        cases_ability = np.array(cases_ability)
        
        # 解决中文显示问题
        plt.rcParams["font.sans-serif"] = ["SimHei"]  # 指定默认字体
        plt.rcParams["axes.unicode_minus"] = False  # 解决保存图像是负号"-"显示为方块的问题
        # plt.style.use(style='classic')  # 设置ggplot样式
        
        results = list()
        for ability in cases_ability:
            keys = [
                r"$E^{\pi_{M}}_{\alpha}$", 
                r"$E^{\pi_{P}}_{\alpha}$",
                r"$E^{\pi_{D}}_{\alpha}$", 
                r"$E^{\pi_{E}}_{\alpha}$", 
                r"$E^{\pi_{C}}_{\alpha}$"
            ]
            result = dict()
            for key, value in zip(keys, ability):
                result[key] = value
            results.append(result)
        data_length = len(results[0])
        angles = np.linspace(0, 2 * np.pi, data_length, endpoint=False)  # 将极坐标根据数据长度进行等分
        
        # 分离属性字段和数据
        labels = [key for key in results[0].keys()]
        score = [[v for v in result.values()] for result in results]
        
        # 使雷达图数据封闭
        angles = np.concatenate((angles, [angles[0]]))
        labels = np.concatenate((labels, [labels[0]]))
        score_First  = np.concatenate((score[0], [score[0][0]]))
        score_Second = np.concatenate((score[1], [score[1][0]]))
        score_Third  = np.concatenate((score[2], [score[2][0]]))
        score_Fourth = np.concatenate((score[3], [score[3][0]]))
        
        # 设置图形的大小
        fig = plt.figure(figsize=(10, 8), dpi=300)
        # 新建一个子图
        ax = plt.subplot(111, polar=True)
        # 绘制雷达图并填充颜色
        ax.plot(angles, score_First,  color="orange", label=r"$\alpha_1$ ({})".format(cases_Q[0]))
        ax.plot(angles, score_Second, color="blue",   label=r"$\alpha_2$ ({})".format(cases_Q[1]))
        ax.plot(angles, score_Third,  color="red",    label=r"$\alpha_3$ ({})".format(cases_Q[2]))
        ax.plot(angles, score_Fourth, color="green",  label=r"$\alpha_4$ ({})".format(cases_Q[3]))
        ax.fill(angles, score_First,  "orange", alpha=0.4)
        ax.fill(angles, score_Second, "blue",   alpha=0.4)
        ax.fill(angles, score_Third,  "red",    alpha=0.4)
        ax.fill(angles, score_Fourth, "green",  alpha=0.4)
        
        # 设置雷达图中每一项的标签显示
        ax.set_thetagrids(angles * 180 / np.pi, labels, fontsize=20)
        ax.set_theta_zero_location("E")  # 设置0度坐标轴起始位置，东西南北
        ax.set_rlim(0, 1)                # 设置雷达图的坐标刻度范围
        ax.set_rlabel_position(270)      # 设置雷达图的坐标值显示角度，相对于起始角度的偏移量
        ax.set_title(file_name, fontsize=25)
        plt.legend(frameon=False, loc= 'upper right', fontsize=15)
        plt.show()
        
        # (3) Table 7-10 线性回归
        # 自变量: 截止2000年的估计值
        X = np.concatenate([
            [q_mu_list], 
            [DS_mu_list], 
            [PS_mu_list], 
            [MS_mu_list], 
            [ES_mu_list], 
            [CS_mu_list]
        ])
        X = X.T
        X = sm.add_constant(X)
        # 因变量: 截止2010年的传统指标
        # N_list, C_list, CS_list, H_list
        Y = np.log(np.array(N_list) + 1)
        
        ols = sm.OLS(Y, X)
        res = ols.fit()
        print(res.summary())
        
        
        # Appendix. A / the distribution of the dependent variables and independent variables
        """ computer science """
        # computer science - N_alpha
        Y = N_list
        xlabel = r"$N_{\alpha}$"
        hist_color = 'gray'
        kde_color = 'black'
        xticks = np.arange(0, 350, 50)
        yticks = np.arange(0, 0.05, 0.01)
        
        # computer science - C_alpha
        Y = np.array(C_list)
        Y = Y[Y <= 10000]
        xlabel = r"$C_{\alpha}$"
        hist_color = 'gray'
        kde_color = 'black'
        xticks = np.arange(0, 12000, 2000)
        yticks = np.arange(0, 0.0018, 0.0003)
        
        # computer science - C_alpha-star
        Y = np.array(CS_list)
        Y = Y[Y <= 2000]
        xlabel = r"$C_{\alpha}^{*}$"
        hist_color = 'gray'
        kde_color = 'black'
        xticks = np.arange(0, 2500, 500)
        yticks = np.arange(0, 0.010, 0.002)
        
        # computer science - H_alpha
        Y = H_list
        xlabel = r"$H_{\alpha}$"
        hist_color = 'gray'
        kde_color = 'black'
        xticks = np.arange(0, 100, 20)
        yticks = np.arange(0, 0.12, 0.02)
        
        # computer science - Q_alpha
        Y = q_mu_list
        xlabel = r"$Q_{\alpha}$"
        hist_color = 'plum'
        kde_color = 'fuchsia'
        xticks = np.arange(0, 3, 0.5)
        yticks = np.arange(0, 3, 0.5)
        
        # computer science - E_M
        Y = MS_mu_list
        xlabel = r"$E_{\alpha}^{\pi_M}$"
        hist_color = 'green'
        kde_color = 'green'
        xticks = np.arange(-10, 15, 5)
        yticks = np.arange(0, 0.5, 0.1)
        
        # computer science - E_P
        Y = PS_mu_list
        xlabel = r"$E_{\alpha}^{\pi_P}$"
        hist_color = 'orange'
        kde_color = 'orange'
        xticks = np.arange(-1, 5, 1)
        yticks = np.arange(0, 1.6, 0.3)
        
        # computer science - E_D
        Y = DS_mu_list
        xlabel = r"$E_{\alpha}^{\pi_D}$"
        hist_color = 'red'
        kde_color = 'red'
        xticks = np.arange(-4, 5, 1)
        yticks = np.arange(0, 1.0, 0.2)
        
        # computer science - E_E
        Y = ES_mu_list
        xlabel = r"$E_{\alpha}^{\pi_E}$"
        hist_color = 'blue'
        kde_color = 'blue'
        xticks = np.arange(-1, 5, 1)
        yticks = np.arange(0, 1.5, 0.3)
        
        # computer science - E_C
        Y = CS_mu_list
        xlabel = r"$E_{\alpha}^{\pi_C}$"
        hist_color = 'black'
        kde_color = 'black'
        xticks = np.arange(-1, 5, 1)
        yticks = np.arange(0, 1.5, 0.3)
        
        """ physics """
        # physics - N_alpha
        Y = N_list
        xlabel = r"$N_{\alpha}$"
        hist_color = 'gray'
        kde_color = 'black'
        xticks = np.arange(0, 350, 50)
        yticks = np.arange(0, 0.05, 0.01)
        
        # physics- C_alpha
        Y = np.array(C_list)
        Y = Y[Y <= 10000]
        xlabel = r"$C_{\alpha}$"
        hist_color = 'gray'
        kde_color = 'black'
        xticks = np.arange(0, 12000, 2000)
        yticks = np.arange(0, 0.0018, 0.0003)
        
        # physics - C_alpha-star
        Y = np.array(CS_list)
        Y = Y[Y <= 2000]
        xlabel = r"$C_{\alpha}^{*}$"
        hist_color = 'gray'
        kde_color = 'black'
        xticks = np.arange(0, 2500, 500)
        yticks = np.arange(0, 0.010, 0.002)
        
        # physics - H_alpha
        Y = H_list
        xlabel = r"$H_{\alpha}$"
        hist_color = 'gray'
        kde_color = 'black'
        xticks = np.arange(0, 100, 20)
        yticks = np.arange(0, 0.16, 0.03)
        
        # physics - Q_alpha
        Y = q_mu_list
        xlabel = r"$Q_{\alpha}$"
        hist_color = 'plum'
        kde_color = 'fuchsia'
        xticks = np.arange(0, 2.5, 0.5)
        yticks = np.arange(0, 5, 1)
        
        # physics - E_M
        Y = MS_mu_list
        xlabel = r"$E_{\alpha}^{\pi_M}$"
        hist_color = 'green'
        kde_color = 'green'
        xticks = np.arange(-10, 15, 5)
        yticks = np.arange(0, 0.65, 0.15)
        
        # physics - E_P
        Y = PS_mu_list
        xlabel = r"$E_{\alpha}^{\pi_P}$"
        hist_color = 'orange'
        kde_color = 'orange'
        xticks = np.arange(-1, 5, 1)
        yticks = np.arange(0, 1.6, 0.3)
        
        # physics - E_D
        Y = DS_mu_list
        xlabel = r"$E_{\alpha}^{\pi_D}$"
        hist_color = 'red'
        kde_color = 'red'
        xticks = np.arange(-2, 3, 1)
        yticks = np.arange(0, 1.6, 0.3)
        
        # physics - E_E
        Y = ES_mu_list
        xlabel = r"$E_{\alpha}^{\pi_E}$"
        hist_color = 'blue'
        kde_color = 'blue'
        xticks = np.arange(-1, 4, 1)
        yticks = np.arange(0, 1.6, 0.3)
        
        # physics - E_C
        Y = CS_mu_list
        xlabel = r"$E_{\alpha}^{\pi_C}$"
        hist_color = 'black'
        kde_color = 'black'
        xticks = np.arange(-1, 5, 1)
        yticks = np.arange(0, 1.5, 0.3)
        
        """ chemistry """
        # chemistry - N_alpha
        Y = N_list
        xlabel = r"$N_{\alpha}$"
        hist_color = 'gray'
        kde_color = 'black'
        xticks = np.arange(0, 350, 50)
        yticks = np.arange(0, 0.06, 0.01)
        
        # chemistry- C_alpha
        Y = np.array(C_list)
        Y = Y[Y <= 10000]
        xlabel = r"$C_{\alpha}$"
        hist_color = 'gray'
        kde_color = 'black'
        xticks = np.arange(0, 12000, 2000)
        yticks = np.arange(0, 0.0018, 0.0003)
        
        # chemistry - C_alpha-star
        Y = np.array(CS_list)
        Y = Y[Y <= 2000]
        xlabel = r"$C_{\alpha}^{*}$"
        hist_color = 'gray'
        kde_color = 'black'
        xticks = np.arange(0, 2500, 500)
        yticks = np.arange(0, 0.012, 0.002)
        
        # chemistry - H_alpha
        Y = H_list
        xlabel = r"$H_{\alpha}$"
        hist_color = 'gray'
        kde_color = 'black'
        xticks = np.arange(0, 100, 20)
        yticks = np.arange(0, 0.16, 0.03)
        
        # chemistry - Q_alpha
        Y = q_mu_list
        xlabel = r"$Q_{\alpha}$"
        hist_color = 'plum'
        kde_color = 'fuchsia'
        xticks = np.arange(0, 3, 0.5)
        yticks = np.arange(0, 3, 0.5)
        
        # chemistry - E_M
        Y = MS_mu_list
        xlabel = r"$E_{\alpha}^{\pi_M}$"
        hist_color = 'green'
        kde_color = 'green'
        xticks = np.arange(-10, 15, 5)
        yticks = np.arange(0, 0.65, 0.15)
        
        # chemistry - E_P
        Y = PS_mu_list
        xlabel = r"$E_{\alpha}^{\pi_P}$"
        hist_color = 'orange'
        kde_color = 'orange'
        xticks = np.arange(-1, 5, 1)
        yticks = np.arange(0, 1.6, 0.3)
        
        # chemistry - E_D
        Y = DS_mu_list
        xlabel = r"$E_{\alpha}^{\pi_D}$"
        hist_color = 'red'
        kde_color = 'red'
        xticks = np.arange(-2, 3, 1)
        yticks = np.arange(0, 1.6, 0.3)
        
        # chemistry - E_E
        Y = ES_mu_list
        xlabel = r"$E_{\alpha}^{\pi_E}$"
        hist_color = 'blue'
        kde_color = 'blue'
        xticks = np.arange(-1, 4, 1)
        yticks = np.arange(0, 1.6, 0.3)
        
        # chemistry - E_C
        Y = CS_mu_list
        xlabel = r"$E_{\alpha}^{\pi_C}$"
        hist_color = 'black'
        kde_color = 'black'
        xticks = np.arange(-1, 5, 1)
        yticks = np.arange(0, 1.5, 0.3)
        
        
        rcParams['axes.unicode_minus'] = False
        fig = plt.figure(figsize=(8, 6))
        plt.rcParams['savefig.dpi'] = 400
        plt.rcParams['figure.dpi'] = 400
        config = {
                  "font.family" : "Times New Roman",
                  "font.size" : 20
                  }
        rcParams.update(config)
        
        sns.distplot(Y, kde=True, hist=True,
                     hist_kws = {'rwidth':1, 'color':hist_color, "edgecolor":"white", "histtype": "bar", 'linewidth':1, 'alpha':0.7, "label": r"",
                                 },
                     kde_kws  = {"color": kde_color, "alpha":0.45, "linewidth": 2, "linestyle": "--", "fill":False, "label": ""},)
        plt.ylabel("Density")
        plt.xlabel(xlabel)
        plt.xticks(xticks)
        plt.xlim(-1, 4)
        # # plt.ylim(0, 1.2)
        plt.yticks(yticks)
        plt.title(file_name)